---
title: "Data 624 Project 2"
author: "Zach Herold, Anthony Pagan, Betsy Rosalen"
date: "5/10/2020"
output: 
    html_document:
        toc: true
        toc_float: true
        toc_depth: 5
        css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
knitr::opts_chunk$set(echo = TRUE)
require(knitr)
library(ggplot2)
library(tidyr)
library(MASS)
library(psych)
library(kableExtra)
library(dplyr)
library(faraway)
library(gridExtra)
library(reshape2)
library(leaps)
library(pROC)
library(caret)
library(naniar)
library(pander)
library(pROC)
library(mlbench)
library(e1071)
library(fpp2)
library(lubridate)
library(readxl)
library(MASS)
library(reshape)
library(urca)
library(tseries)
library(tidyr)
library(ZIM)
library(earth)
library(AppliedPredictiveModeling)
```

# Project 2 Description 

This is role playing. I am your new boss. I am in charge of production at ABC Beverage and you are a team of data scientists reporting to me. My leadership has told me that new regulations are requiring us to understand our manufacturing process, the predictive factors and be able to report to them our predictive model of PH.Please use the historical data set I am providing.  Build and report the factors in BOTH a technical and non-technical report. I like to use Word and Excel. Please provide your non-technical report in a  business friendly readable document and your predictions in an Excel readable format. The technical report should show clearly the models you tested and how you selected your final approach. Please submit both Rpubs links and .rmd files or other readable formats for technical and non-technical reports. Also submit the excel file showing the prediction of your models for pH.

# Data Review/Cleanup

```{r}
#Import Data
stEval<- read.csv("https://raw.githubusercontent.com/apag101/data624Group5/master/Project2/StudentEvaluation.csv?token=AB3M6K7RXH65YIAKWZBQ6KK6XA7R2", header = TRUE)
stData<- read.csv("https://raw.githubusercontent.com/apag101/data624Group5/master/Project2/StudentData.csv?token=AB3M6K4AYHCT5HBFJYHCCSC6XBACQ", header = TRUE)

#Review Data
glimpse(stData)

#Update factor
stData$Brand.Code<-as.factor(stData$Brand.Code)

#Missing Data
vis_miss(stData)
summary(complete.cases(stData))
cstData<-subset(stData[-1], complete.cases(stData))

describe(cstData)
describe(stData[-1])
glimpse(cstData)

#plot checks
histogram(cstData$PH)
featurePlot(cstData,cstData$PH)
```

```{r}
#Correlation Matrix
library(corrplot)
cor.plt <- cor(cstData, use = "pairwise.complete.obs", method = "pearson")
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor.plt, method="color", col=col(200),  
         type="upper", order="hclust",
         tl.col="black", tl.srt=45, tl.cex=0.5,
         diag=FALSE 
         )
```

# Partition Data

```{r}
#Partition Data
set.seed(123)
trainidx<-sample(nrow(cstData),round(0.7*nrow(cstData)),replace=F)
traindata<-cstData[trainidx,]
testdata<-cstData[-trainidx,]
```

# Models

```{r}
require(caret)
trctrl<- trainControl(method="repeatedcv", number=3,repeats=2)

##Linear Regression
linreg <- caret::train(PH~., data=traindata, method="lm", 
                trControl=trctrl)
linPred <- predict(linreg, newdata = testdata)
c('linPred:',postResample(pred = linPred, obs = testdata$PH)) #0.1414880 0.3775156

##Ridge Regression
ridge <- caret::train(PH~., data=traindata, method="ridge", 
                trControl=trctrl)
ridgePred <- predict(ridge, newdata = testdata)
c('ridgePred:',postResample(pred = ridgePred, obs = testdata$PH)) #0.1414837 0.3775762

##Lasso Regression
lasso <- caret::train(PH~., data=traindata, method="lasso", 
                trControl=trctrl)
lassoPred <- predict(lasso, newdata = testdata)
c('lassoPred:',postResample(pred = lassoPred, obs = testdata$PH)) #0.1418941 0.3762947

##RandomForest (Processed)
rforest <- caret::train(PH~., data=traindata, method="cforest", 
                trControl=trctrl,
                tuneLength =2)
forPred <- predict(rforest, newdata = testdata)
c('forPred:',postResample(pred = forPred, obs = testdata$PH)) #0.11550844 0.59451507

##Tree Bag
bag <- caret::train(PH~., data=traindata, method="treebag", 
                trControl=trctrl,
                tuneLength =2)
bagPred <- predict(bag, newdata = testdata)
c('bagPred:',postResample(pred = bagPred, obs = testdata$PH)) #0.12790436 0.50718903

##CTree
ctre <- caret::train(PH~., data=traindata, method="ctree2", 
                trControl=trctrl,
                tuneLength =2)
ctrePred <- predict(ctre, newdata = testdata)
c('ctrePred:',postResample(pred = ctrePred, obs = testdata$PH)) #0.1519582 0.2804008

##CART
rcart<- caret::train(PH~., data=traindata, method="rpart",
                trControl=trctrl,
                tuneLength =2)
cartPred <- predict(rcart, newdata = testdata)
c('cartPred:',postResample(pred = cartPred, obs = testdata$PH)) #0.1593219 0.2053639

##MARS
marsFit <- earth(PH~., data = traindata, degree=2, nprune=14)
marsPred <- predict(marsFit, newdata = testdata)
c('marsPred:',postResample(pred = marsPred, obs = testdata$PH)) #0.1399919 0.3912855

##KNN
knnGrid <-  expand.grid(k = 1:20)
knnFit <- caret::train(PH~., data = traindata, 
                method = "knn",
                trControl = trctrl, 
                tuneGrid = knnGrid)
knnPred <- predict(knnFit, newdata = testdata)
c('knnPred:',postResample(pred = knnPred, obs = testdata$PH)) #0.1278504 0.5088682

##SVM (Radial Kernel)
svmGrid <-  expand.grid(C = c(1,1000))
svmFit <- caret::train(PH~., data = traindata, 
                 #type='eps-regression',
                 method = 'svmRadialCost', 
                 trControl = trctrl, 
                 tuneGrid = svmGrid)
svmPred <- predict(svmFit, newdata = testdata)
c('svmPred:', postResample(pred = svmPred, obs = testdata$PH)) #0.13136218 0.48751241
```


```{r}
#Variable Importance Ranking (Random Forest)
rfImp <- varImp(rforest, scale = FALSE)
bookTheme()
plot(rfImp, top=15, scales = list(y = list(cex = 0.8)))
```

```{r}
rfImp
```

### Top Five Most Important 
Mnf.Flow	0.0186774450			
Alch.Rel	0.0063442447			
Usage.cont	0.0032824948			
Pressure.Vacuum	0.0017275495			
Temperature	0.0016837020	


```{r}
#install.packages('rpart.plot')
library(rpart.plot)
tree <- rpart(PH~., data=traindata)
prp(tree)
```


```{r}
library(randomForest)
#Using full dataset (applying na.roughfix to missing values)
cstData_all<-subset(stData[-1])
set.seed(123)
trainidx2<-sample(nrow(cstData_all),round(0.7*nrow(cstData_all)),replace=F)
traindata2<-cstData_all[trainidx2,]
testdata2<-cstData_all[-trainidx2,]

##Additional Random Forest tuning (TUNE HERE)
#rf.model2 <- randomForest(PH~., data=traindata2, na.action=na.roughfix)
rf.model2 <- randomForest(PH~., data=traindata2, na.action=na.roughfix, importance=TRUE) 
rfPred2 <- predict(rf.model2, newdata = testdata2)
postResample(pred = rfPred2, obs = testdata2$PH) #0.1097018 0.6173039
```

```{r}
#with importance=TRUE, uses approach by Breiman to calculate the variable importance reported as MeanDecreaseAccuracy
#https://stackoverflow.com/questions/37888619/difference-between-varimp-caret-and-importance-randomforest-for-random-fores
rfImp2 <- as.data.frame(importance(rf.model2, scale = FALSE))
rfImp2[order(-rfImp2[,2]),]
```

### Top Five Most Important 
Mnf.Flow	1.215420e-02	6.8574948		
Usage.cont	5.769698e-03	4.5754067		
Bowl.Setpoint	5.173735e-03	2.8063547		
Temperature	2.667381e-03	2.6427466		
Carb.Rel	3.768302e-03	2.4322423



```{r}
##Linear Regression using only top 2 variables (Mnf.Flow & Usage.cont)
linreg2 <- caret::train(PH~Mnf.Flow+Usage.cont+Alch.Rel+Temperature, data=traindata, method="lm", 
                trControl=trctrl)
summary(linreg2) # Adjusted R-squared:  0.2785
```

__note the negative coefficients of Mnf.Flow, Usage.conf, Temperature; positive of Alch.Rel__


```{r}
#Visualing the Mnf.Flow column 
plot(stData$Mnf.Flow, stData$PH)
hist(stData$Mnf.Flow)
```


```{r}
#Investigating percent of null values in ranged bins of Mnf.Flow 
nrow(stData) #2571 rows
sum(!complete.cases(stData)) #442 rows with missing data

neg.Mnf.Flow.count <- nrow(stData[stData$Mnf.Flow < 0,]) #1186 rows with negative values
neg.complete.Mnf.Flow.count <- sum(complete.cases(stData[stData$Mnf.Flow < 0,])) #989 complete cases
neg.complete.Mnf.Flow.count / neg.Mnf.Flow.count #0.8338954

nearzeros.Mnf.Flow.count <- nrow(stData[stData$Mnf.Flow >= 0 & stData$Mnf.Flow <= 1 ,]) #81 rows
nearzeros.complete.Mnf.Flow.count <-sum(complete.cases(stData[stData$Mnf.Flow >= 0 & stData$Mnf.Flow <= 1 ,]))
nearzeros.complete.Mnf.Flow.count / nearzeros.Mnf.Flow.count #0.01234568 1% of data complete

pos.Mnf.Flow.count <- nrow(stData[stData$Mnf.Flow > 1,]) #1308 total rows with with Mnf.Flow greater than 50
pos.complete.Mnf.Flow.count <- sum(complete.cases(stData[stData$Mnf.Flow > 1,])) #1140 complete cases with Mnf.Flow greater than 50
pos.complete.Mnf.Flow.count / pos.Mnf.Flow.count #0.8707951 87% of data complete


nearzeros.Mnf.Flow.count / nrow(stData) #.03150 3% of the total number of rows accounts for 18% of the missing values

```


```{r}
#Finding the mean of the Mnf.FLow from subset of values greater than 1, used in binning
#pos.Mnf.Flow <- stData[stData$Mnf.Flow > 1,]
#mean(pos.Mnf.Flow$Mnf.Flow, na.rm = T)
```


```{r}
#Separating the Mnf.Flow column by thresholds
stData$Mnf.Flow_ord <- cut(
  stData$Mnf.Flow,
  breaks = c(-Inf, -1, 1, 140, Inf),
  labels = c(1, 2, 3, 4),
  right  = FALSE
)
table(stData$Mnf.Flow_ord)
```

```{r}
#Violin plot of Mnf.Flow by bins
g <-ggplot(stData, aes(x=factor(stData$Mnf.Flow_ord), y=stData$PH))
g+geom_violin(alpha=0.5, color='grey') +
  geom_jitter(alpha=0.5, size=4, aes(), position = position_jitter(width = 0.1), color='darkblue', show.legend=FALSE) +
  ggtitle("PH by Mnf.Flow classification") +
  coord_flip()
```


```{r}
#Subsetting data by brand
brandA <- stData[stData$Brand.Code == 'A',]
brandB <- stData[stData$Brand.Code == 'B',]
brandC <- stData[stData$Brand.Code == 'C',]
brandD <- stData[stData$Brand.Code == 'D',]
```

```{r}

###Add Trimmed Means to NA Value
r <- colnames(cstData_all)[ apply(cstData_all, 2, anyNA)]

cstData_all[,colnames(cstData_all) %in% r]<-data.frame(sapply(cstData_all[,colnames(cstData_all) %in% r],
      function(x) ifelse(is.na(x),
            mean(x, na.rm = TRUE, trim = .1),
            x)))
```


```{r}

#BrandA Training/Test Splitting
set.seed(123)
trainidxA<-sample(nrow(brandA),round(0.7*nrow(brandA)),replace=F)
traindataA<-cstData_all[trainidxA,]
testdataA<-cstData_all[-trainidxA,]


##RandomForest (on BrandA)
trctrl<- trainControl(method="repeatedcv", number=2,repeats=2)
rforestA <- caret::train(PH~., data=traindataA, method="cforest", 
                trControl=trctrl, tuneLength =2, na.action=na.omit)
forPredA <- predict(rforestA, newdata = testdataA)
postResample(pred = forPredA, obs = testdataA$PH) #why NA?
```


```{r}
#Variable Importance Ranking (on Brand A)
rfImpA <- varImp(rforestA, scale = FALSE)
plot(rfImpA, top=15, scales = list(y = list(cex = 0.8)))
```

# Appendix

**Code used in analysis**
```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}

```

